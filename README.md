# ğŸ–Šï¸ Pen and Paper  
### Transform handwritten notes into searchable, conversational knowledge.  

> From ink to insight â€” powered by OCR, Meilisearch, Google AI, and ElevenLabs.

---

## ğŸš€ Overview  
**Pen and Paper** is a full-stack application that digitizes handwritten notes, indexes them for semantic search, and enables users to *chat* with their own handwritten content.  

It uses **OCR (Optical Character Recognition)** to extract text from uploaded images or PDFs, then builds a **RAG (Retrieval-Augmented Generation)** pipeline with **Meilisearch** and **Google Generative AI**.  
To make it even more interactive, it integrates **ElevenLabs TTS/STT** for natural voice responses and speech input.

---

## ğŸ§  Inspiration  
Most great ideas start with a pen and paper â€” in classrooms, meetings, or brainstorming sessions.  
But once written, theyâ€™re often forgotten or unsearchable.  
**Pen and Paper** bridges the gap between analog creativity and digital intelligence by turning handwritten notes into structured, searchable, and conversational data.

---

## ğŸ’¡ Features  
- ğŸ“ **OCR for Handwriting** â€” Uses Google Gemma3 4b to extract text from handwritten pages.  
- ğŸ” **Instant Search** â€” Meilisearch provides lightning-fast document indexing and retrieval.  
- ğŸ—£ï¸ **Conversational AI** â€” Ask natural questions; responses are grounded in your own notes.  
- ğŸ”Š **Voice Interaction** â€” ElevenLabs TTS/STT for lifelike speech output and voice queries.  
- ğŸ” **Multi-tenant Authentication** â€” Users only access their own data, protected by JWT.  
- ğŸ§© **Modular Architecture** â€” Easily replace APIs with local models for self-hosted setups.  

---

## ğŸ—ï¸ Tech Stack  

### Backend  
- **FastAPI** â€” API, authentication, file handling, image preprocessing and pipeline orchestration  
- **Google Gemma3 4b** â€” OCR for handwritten text  
- **Meilisearch** â€” Document indexing and retrieval  
- **Google Gemma3 4b** â€” Contextual question answering (RAG)  
- **ElevenLabs API** â€” Text-to-Speech (TTS) and Speech-to-Text (STT)  
- **Supabase** â€” Secure file storage, user management and blob storage  

### Frontend  
- **React + Vite** â€” Clean, responsive UI   

---

## âš™ï¸ How It Works  

1. **User uploads handwritten notes** (images or PDFs).  
2. **FastAPI backend** sends them to the **Google Gemma3 4b** for OCR.  
3. Extracted text is indexed in **Meilisearch** under the userâ€™s unique namespace.  
4. When a query is made:  
   - Relevant context is fetched from Meilisearch.  
   - Context and query are passed to **Gemma LLM** for RAG-based response.  
   - Optionally, ElevenLabs converts the answer into speech.  
5. **React frontend** displays both the text and the voice response.  

---

## ğŸ§© Architecture  

```text
+-------------+        +----------------+       +------------------+
|  React UI   | <----> |   FastAPI API  | <-->  |  Meilisearch DB  |
| (Frontend)  |        | (Backend)      |       +------------------+
+-------------+        |   |    |       |       +------------------+
                       |   |    |       | <-->  | Google Vision API |
                       |   |    |       | <-->  | Google Generative |
                       |   |    |       | <-->  | ElevenLabs API    |
                       +----------------+       +------------------+
